<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Rich's Home</title>
  
  <meta name="author" content="Ruiqi(Rich) Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/gif" href="images/paimon.gif">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ruiqi(Rich) Zhang</name>
              </p>
              <p>I'm an undergraduate in Automotive Engineering @ Tongji University and a researcher of <a href="https://ispc-group.github.io/">ISPC Group</a> supervised by Prof. Guang Chen. My research mainly focuses on Robotics, Reinforcement Learning and Computer Vision. 
		 In the 2022 spring, I joined the Robotics Institute of Carnegie Mellon University and cooperated with <a href="https://www.ri.cmu.edu/ri-faculty/ji-zhang/">Prof. Ji Zhang</a>. We developed an autonomous exploration toolkit via NVIDIA IsaacSim. In the 2022 summer, I joined the School of Computing of National University of Singapore and cooperated with <a href="https://linsats.github.io/">Prof. Lin Shao</a> and <a href="https://yusufma03.github.io/">Xiao Ma</a>. We developed a gradient-based RL algorithm via differentiable simulator.</a>
              </p>
              <p>
                In 2023 FALL, I will join the <a href="https://hiperlab.berkeley.edu/">HiPeR Lab</a> @ UC Berkeley and begin my happy journal with <a href="https://scholar.google.com/citations?user=yQxs7qUAAAAJ&hl=zh-CN&oi=ao/">Prof. Mark W. Mueller</a> :)
              </p>
          
              <p style="text-align:center">
                <a href="mailto:richzhang@berkeley.edu">Email</a> &nbsp/&nbsp
                <a href="data/cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=zh-CN&user=C-RORV0AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/ruiqizhang99/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="images/rich.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/rich.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>- [Sep. 2022] 1 paper for Multi-Agent Navigation has been accepted to <strong>IEEE MFI</strong> <font color="red">(Best student paper)</font>.</p>
            <p>- [Aug. 2022] I'm joining National University of Singapore, cooperating with Prof. Lin Shao</p>
            <p>- [Jul. 2022] 1 paper for F1Tenth Autonomous Racing has been accepted to <strong>IEEE RA-L</strong> <font color="red">(My first Paper)</font>!</p>
            <p>- [Apr. 2022] I'm joining Carnegie Mellon University Robotics Institute, cooperating with Prof. Ji Zhang</p>
            <p>- [Dec. 2021] 1 paper for Relative Pose Estimation has been accepted to Frontiers in NeuroRobotics.</p>
            <p>- [Aug. 2020] I'm joining <strong>ISPC-Lab</strong> as a research scientist working on reinforcement learning.</p>
          </td>
        </tr>
      </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Publications</heading>
            </td>
          </tr>
          
        </tbody></table>


            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='data/zhang2022residual/residual.png' width="160">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9834085">
              <papertitle>Residual Policy Learning Facilitates Efficient Model-Free Autonomous Racing</papertitle>
              </a>
              <br>
              <strong>Ruiqi Zhang</strong>,
              <a href="https://scholar.google.com/citations?user=8mO6YIMAAAAJ&hl=zh-CN">Jing Hou</a>,
              <a href="https://ispc-group.github.io/">Guang Chen*</a>,
              <a href="https://scholar.google.com/citations?user=xxUvEtIAAAAJ&hl=zh-CN">Zhijun Li</a>,
              Jianxiao Chen,
              <a href="https://scholar.google.com/citations?user=-CA8QgwAAAAJ&hl=zh-CN">Alois Knoll</a>
              <br>
		<em>IEEE Robotics and Automation Letters</em>, 2022
              <br>
              <a href="https://ieeexplore.ieee.org/document/9834085">pdf</a>
              /
              <a href="data/zhang2022residual/zhang2022residual.bib">bibtex</a>
              <p>We develop an efficient residual policy learning algorithm with modified artificial potential field for autonomous racing, which leverages complementary property of MAPF and model-free DRL. Meanwhile, we validate its robustness, generalization ability, real-time performance and lap time on 5 tracks of F1Tenth competition. Experimental results show our method outperforms the state-of-the-art method Dreamer and reaches the comparable level of professional human players.</p>
            </td>



            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='data/zhang2022pipo/pipo.png' width="160">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9913862">
              <papertitle>PIPO: Policy Optimization with Permutation-Invariant Constraint for Distributed Multi-Robot Navigation</papertitle>
              </a>
              <br>
              <strong>Ruiqi Zhang</strong>,
              <a href="https://ispc-group.github.io/">Guang Chen*</a>,
              <a href="https://scholar.google.com/citations?user=8mO6YIMAAAAJ&hl=zh-CN">Jing Hou</a>,
              <a href="https://scholar.google.com/citations?user=xxUvEtIAAAAJ&hl=zh-CN">Zhijun Li</a>,
              <a href="https://scholar.google.com/citations?user=-CA8QgwAAAAJ&hl=zh-CN">Alois Knoll</a>
              <br>
		<em>IEEE International Conference on Multisensor Fusion and Integration</em>, 2022 &nbsp <font color="red">(best student paper)</font>
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9913862">pdf</a>
              /
              <a href="data/zhang2022pipo/pipo.png">bibtex</a>
              <p>We propose a decentralized reinforcement learning method via graph convolutional network. Our method utilizes the permutation-invariant property in multi-agent system to enhance the representation and generalization ability of actor-critic network. Experimental results show our method is much safer than centralized MARL baselines and constrained barrier function-based methods and can be generalized to arbitrary number of agents.</p>
            </td>
		    
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Pre-Prints</heading>
            </td>
          </tr>
          
        </tbody></table>


            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='data/hou2023spreeze/spreeze.png' width="160">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9834085">
              <papertitle>Spreeze: High-Throughput Parallel Reinforcement Learning Framework</papertitle>
              </a>
              <br>
	      <a href="https://scholar.google.com/citations?user=8mO6YIMAAAAJ&hl=zh-CN">Jing Hou</a>,
              <a href="https://ispc-group.github.io/">Guang Chen*</a>,
	      <strong>Ruiqi Zhang</strong>,
              <a href="https://scholar.google.com/citations?user=xxUvEtIAAAAJ&hl=zh-CN">Zhijun Li</a>,
              <a href="https://scholar.google.com/citations?user=E1GCDXUAAAAJ&hl=zh-CN&oi=ao">Shangding Gu</a>, 
	      <a href="https://www.cae.cn/cae/html/main/colys/26976335.html">Changjun Jiang</a>
              <br>
		<em>IEEE Transactions on Parallel and Distributed Systems (under review)</em>, 2022
              <br>
              <a href="data/hou2023spreeze/hou2023spreeze.pdf">pdf</a>
		    /
		    bibtex
              <p> We propose a high-performance RL frameworks called Spreeze, which asynchronously parallelizes the experience sampling, network update, performance evaluation, and visualization
		operations, and employs multiple efficient data transmission techniques to transfer various types of data between processes. The
		framework can automatically adjust the parallelization hyperparameters based on the computing ability of the hardware device in order
		to perform efficient large-batch updates.</p>
            </td>

		    
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Survice</heading>
            <p>- Conference Reviewer: ICRA 2023</p>
            <p>- Journal Reviewer: IEEE T-ASE, Frontiers in NeuroRobotics</p>
          </td>
        </tr>
      </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Stolen from <a href="https://github.com/jonbarron/website">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
